{
  "6": {
    "inputs": {
      "text": "make the man walk towards the camera, stop and then turned arround.",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "58",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "umt5_xxl_fp16.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "50": {
    "inputs": {
      "width": 480,
      "height": 832,
      "length": 81,
      "batch_size": 1,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "start_image": [
        "152",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "WanImageToVideo"
    }
  },
  "52": {
    "inputs": {
      "image": "IMG_0053.JPG"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "54": {
    "inputs": {
      "shift": 6.500000000000001,
      "model": [
        "64",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "HIGH ModelSamplingSD3"
    }
  },
  "55": {
    "inputs": {
      "shift": 6.500000000000001,
      "model": [
        "65",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "LOW ModelSamplingSD3"
    }
  },
  "57": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 640251573954510,
      "steps": 6,
      "cfg": 1,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "start_at_step": 0,
      "end_at_step": 2,
      "return_with_leftover_noise": "enable",
      "model": [
        "54",
        0
      ],
      "positive": [
        "50",
        0
      ],
      "negative": [
        "50",
        1
      ],
      "latent_image": [
        "50",
        2
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler HIGH"
    }
  },
  "58": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": 0,
      "steps": 6,
      "cfg": 1,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "start_at_step": 2,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "55",
        0
      ],
      "positive": [
        "50",
        0
      ],
      "negative": [
        "50",
        1
      ],
      "latent_image": [
        "57",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler LOW"
    }
  },
  "61": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_Q8_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "HIGH (GGUF)"
    }
  },
  "62": {
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_Q8_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "LOW (GGUF)"
    }
  },
  "64": {
    "inputs": {
      "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16.safetensors",
      "strength_model": 1,
      "model": [
        "61",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "HIGH Lora"
    }
  },
  "65": {
    "inputs": {
      "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16.safetensors",
      "strength_model": 1,
      "model": [
        "62",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LOW Lora"
    }
  },
  "152": {
    "inputs": {
      "message": "ğŸ§¹ kmlbdh RAM Cleaner: Cache cleared",
      "images": [
        "52",
        0
      ]
    },
    "class_type": "KMLBDH_RAMCleaner",
    "_meta": {
      "title": "ğŸ§¹ kmlbdh RAM Cleaner"
    }
  },
  "155": {
    "inputs": {
      "anything": [
        "158",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "158": {
    "inputs": {
      "message": "ğŸ§¹ kmlbdh RAM Cleaner: Cache cleared",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "KMLBDH_RAMCleaner",
    "_meta": {
      "title": "ğŸ§¹ kmlbdh RAM Cleaner"
    }
  },
  "163": {
    "inputs": {
      "sub_directory": "videos",
      "filename_text_1": "image",
      "filename_text_2": "wan",
      "filename_text_3": "22",
      "filename_separator": "_",
      "timestamp": "false",
      "counter_type": "folder",
      "filename_text_1_pos": 0,
      "filename_text_2_pos": 1,
      "filename_text_3_pos": 2,
      "timestamp_pos": 3,
      "timestamp_type": "job",
      "counter_pos": 4,
      "extra_metadata": "Extra Metadata",
      "images": [
        "158",
        0
      ]
    },
    "class_type": "Save Images Mikey",
    "_meta": {
      "title": "Save Images Mikey (Mikey)"
    }
  },
  "170": {
    "inputs": {
      "anything": [
        "158",
        0
      ]
    },
    "class_type": "easy clearCacheAll",
    "_meta": {
      "title": "Clear Cache All"
    }
  }
}