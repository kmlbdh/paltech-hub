{
  "3": {
    "inputs": {
      "seed": 900229604572879,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "102",
        0
      ],
      "positive": [
        "97",
        0
      ],
      "negative": [
        "98",
        0
      ],
      "latent_image": [
        "109",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "66": {
    "inputs": {
      "shift": 3,
      "model": [
        "99",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "73": {
    "inputs": {
      "unet_name": "Qwen_Image_Edit-Q8_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "79": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "97": {
    "inputs": {
      "prompt": "the woman is wearing the green tshirt and jeans on the street, fashion photography",
      "clip": [
        "38",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "image": [
        "111",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEdit",
    "_meta": {
      "title": "TextEncodeQwenImageEdit"
    }
  },
  "98": {
    "inputs": {
      "prompt": "",
      "clip": [
        "38",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "image": [
        "111",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEdit",
    "_meta": {
      "title": "TextEncodeQwenImageEdit"
    }
  },
  "99": {
    "inputs": {
      "lora_name": "Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors",
      "strength_model": 1,
      "model": [
        "73",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "102": {
    "inputs": {
      "strength": 1,
      "model": [
        "66",
        0
      ]
    },
    "class_type": "CFGNorm",
    "_meta": {
      "title": "CFGNorm"
    }
  },
  "108": {
    "inputs": {
      "megapixel": "1.0",
      "aspect_ratio": "1:1 (Perfect Square)",
      "divisible_by": "64",
      "custom_ratio": false,
      "custom_aspect_ratio": "1:1"
    },
    "class_type": "FluxResolutionNode",
    "_meta": {
      "title": "Flux Resolution Calc"
    }
  },
  "109": {
    "inputs": {
      "width": [
        "108",
        0
      ],
      "height": [
        "108",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "110": {
    "inputs": {
      "image": "Qwen Image Edit - Clothes 2 Images Woman.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "111": {
    "inputs": {
      "direction": "down",
      "match_image_size": true,
      "spacing_width": 0,
      "spacing_color": "white",
      "image1": [
        "110",
        0
      ],
      "image2": [
        "113",
        0
      ]
    },
    "class_type": "ImageStitch",
    "_meta": {
      "title": "Image Stitch"
    }
  },
  "113": {
    "inputs": {
      "image": "Qwen Image Edit - Clothes 2 Images T-Shirt.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "114": {
    "inputs": {
      "images": [
        "111",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}