{
  "61": {
    "inputs": {
      "vae_name": "ae.sft"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "64": {
    "inputs": {
      "clip_name1": "t5/t5xxl_fp16.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "301": {
    "inputs": {
      "unet_name": "flux1-dev-kontext_fp8_scaled.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "305": {
    "inputs": {
      "pixels": [
        "314",
        0
      ],
      "vae": [
        "61",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "307": {
    "inputs": {
      "conditioning": [
        "308",
        0
      ],
      "latent": [
        "305",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "Reference Latent"
    }
  },
  "308": {
    "inputs": {
      "text": "Make a muslim woman with the face details of the Middle East wear the dress and walk in the street while preserving the dress's details and colors.",
      "clip": [
        "64",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "311": {
    "inputs": {
      "text": "",
      "clip": [
        "64",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "313": {
    "inputs": {
      "filename_prefix": "flux-kontext/img",
      "images": [
        "320",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "314": {
    "inputs": {
      "image": [
        "357",
        0
      ]
    },
    "class_type": "FluxKontextImageScale",
    "_meta": {
      "title": "Flux Kontext"
    }
  },
  "316": {
    "inputs": {
      "guidance": 3,
      "conditioning": [
        "307",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "318": {
    "inputs": {
      "seed": 307133173663637,
      "steps": 20,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "301",
        0
      ],
      "positive": [
        "316",
        0
      ],
      "negative": [
        "311",
        0
      ],
      "latent_image": [
        "355",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "320": {
    "inputs": {
      "samples": [
        "318",
        0
      ],
      "vae": [
        "61",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "355": {
    "inputs": {
      "width": 512,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "357": {
    "inputs": {
      "image": "WhatsApp Image 2025-07-06 at 3.51.14 PM.jpeg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  }
}